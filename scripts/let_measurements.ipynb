{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">\n",
    "\n",
    "# LET measurements\n",
    "\n",
    "<font size=\"3\">\n",
    "    \n",
    "> __Author:__ XXX\n",
    "<br/>__Institute:__ XXX\n",
    "<br/>__Date:__ XX/XX-XXXX\n",
    "\n",
    "_Abstract:_\n",
    "This notebook contains the data-analysis tools used for the measurements at the LET instrument at ISIS. It describes how the analysis was performed, and summarizes the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "    \n",
    "* [1. Introduction](#INTRODUCTION)\n",
    "    * [1.1 Packages](#PACKAGES)\n",
    "    * [1.2 Parameters](#PARAMETERS)\n",
    "    * [1.3 Functions](#FUNCTIONS)\n",
    "* [2. Data](#DATA)\n",
    "    * [2.1 Paths](#PATHS)\n",
    "    * [2.2 Extract](#EXTRACT)\n",
    "    * [2.3 Load](#LOAD)\n",
    "* [3. Filters](#FILTER)\n",
    "* [4. Plotting](#PLOTTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Packages<a class=\"anchor\" id=\"PACKAGES\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoload packages when doing an external change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Activate matplotlib in interactive notebook mode\n",
    "%matplotlib\n",
    "\n",
    "# General packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot, plot\n",
    "\n",
    "# Data handling\n",
    "import mg.file_handling.read as mg_read\n",
    "\n",
    "# Plotting\n",
    "import mg_let.basic_plot as mg_basic_plot\n",
    "\n",
    "# Helper functions\n",
    "import mg.helper_functions.misc as mg_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare all global parameters\n",
    "RAW_FOLDER = '../data/template/raw/'\n",
    "PROCESSED_FOLDER = '../data/template/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Global functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare all functions used in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mg_data(zipped_path, clusters_save_path, events_save_path):\n",
    "    \"\"\"\n",
    "    Function to extract, cluster and save data.\n",
    "    \n",
    "    Args:\n",
    "        zipped_path (str): Location of raw data\n",
    "        clusters_save_path (str): Destination for clusters\n",
    "        events_save_path (str): Destination for events\n",
    "\n",
    "    Yields:\n",
    "        Clusters and events are extracted from the raw data and saved at the specified locations\n",
    "    \n",
    "    \"\"\"\n",
    "    unzipped_path = mg_read.unzip_data(zipped_path)\n",
    "    data = mg_read.import_data(unzipped_path)\n",
    "    # Extract clusters and save to disc\n",
    "    clusters = mg_read.extract_clusters(data)\n",
    "    mg_read.save_data(clusters, clusters_save_path)\n",
    "    clusters = None\n",
    "    # Extract events and save to disc\n",
    "    events = mg_read.extract_events(data)\n",
    "    mg_read.save_data(events, events_save_path)\n",
    "    events = None\n",
    "    # Clear data\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data, cluster, and save to file\n",
    "def extract_and_save(run, raw_path):\n",
    "    \"\"\"\n",
    "    Function to extract, cluster and save data.\n",
    "    \n",
    "    Args:\n",
    "        run (str): File run, as specified in the 'Paths'-declaration below\n",
    "        raw_path (str): Path to the raw data in the '.zip'-file\n",
    "\n",
    "    Yields:\n",
    "        Clusters and events are extracted from the raw data and saved in the 'processed'-folder.\n",
    "    \n",
    "    \"\"\"\n",
    "    clusters_path = PROCESSED_FOLDER + run + '_clu.h5'\n",
    "    events_path = PROCESSED_FOLDER + run + '_ev.h5'\n",
    "    extract_mg_data(raw_path, clusters_path, events_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clusters and events\n",
    "def load_clusters_and_events(run):\n",
    "    \"\"\"\n",
    "    Function to load data from a specific run.\n",
    "    \n",
    "    Args:\n",
    "        run (str): File run, as specified in the 'Paths'-declaration below\n",
    "\n",
    "    Returns:\n",
    "        Clusters (DataFrame)\n",
    "        Events (DataFrame)\n",
    "    \n",
    "    \"\"\"\n",
    "    clusters_path = PROCESSED_FOLDER + run + '_clu.h5'\n",
    "    events_path = PROCESSED_FOLDER + run + '_ev.h5'\n",
    "    return mg_read.load_data(clusters_path), mg_read.load_data(events_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basic(run, clusters_unfiltered, events, df_filter, bus_start, bus_stop, number_rows, area):\n",
    "    \"\"\"\n",
    "    Function to plot all basic plots for SEQUOIA detector,\n",
    "    such as PHS, Coincidences and rate.\n",
    "    \n",
    "    Ordering of plotting is:\n",
    "    \n",
    "    PHS 2D - NOT FILTERED\n",
    "    MULTIPLICITY - FILTERED\n",
    "    PHS 1D - FILTERED\n",
    "    COINCIDENCES 2D - FILTERED\n",
    "    PHS CORRELATION - FILTERED\n",
    "    RATE - FILTERED\n",
    "    TOF - FILTERED\n",
    "    \n",
    "    Note that all plots are filtered except the PHS 2D.\n",
    "    \n",
    "    Args:\n",
    "        run (str): File run\n",
    "        clusters_unfiltered (DataFrame): Unfiltered clusteres\n",
    "        events (DataFrame): Individual events\n",
    "        df_filter (dict): Dictionary specifying the filter which will be used on the clustered data\n",
    "        bus_start (int): First bus to plot\n",
    "        bus_stop (int): Last bus to plot\n",
    "        number_rows (int): Number of rows in plots (number of rows must be larger than number_buses/3)\n",
    "        area (float): Area in m^2 of the active detector surface\n",
    "\n",
    "    Yields:\n",
    "        Plots the basic analysis\n",
    "    \n",
    "    \"\"\"\n",
    "    mg_hf.set_thick_labels(12)\n",
    "    \n",
    "    # Filter clusters\n",
    "    clusters = mg_read.filter_data(clusters_unfiltered, df_filter)\n",
    "    \n",
    "    # Declare parameters\n",
    "    duration = (clusters_unfiltered.time.values[-1] - clusters_unfiltered.time.values[0]) * 62.5e-9\n",
    "    \n",
    "    # PHS - 2D\n",
    "    vmin = 1\n",
    "    vmax = events.shape[0] // 1000 + 100\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(14)\n",
    "    fig.set_figheight(4*number_rows)\n",
    "    for i, bus in enumerate(np.arange(bus_start, bus_stop+1, 1)):\n",
    "        plt.subplot(number_rows, 3, i+1)\n",
    "        events_bus = events[events.bus == bus]\n",
    "        if events_bus.shape[0] > 0:\n",
    "            mg_basic_plot.phs_2d_plot(events_bus, bus, vmin, vmax)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Save data\n",
    "    output_path = '../output/%s_phs_2d.png' % run\n",
    "    fig.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    # Multiplicity\n",
    "    vmin = None\n",
    "    vmax = None\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(14)\n",
    "    fig.set_figheight(4*number_rows)\n",
    "    for i, bus in enumerate(np.arange(bus_start, bus_stop+1, 1)):\n",
    "        plt.subplot(number_rows, 3, i+1)\n",
    "        clusters_bus = clusters[clusters.bus == bus]\n",
    "        if clusters_bus.shape[0] > 1:\n",
    "            mg_basic_plot.multiplicity_plot_perc(clusters_bus, bus, duration)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Save data\n",
    "    output_path = '../output/%s_multiplicity_2d.png' % run\n",
    "    fig.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    # PHS - 1D\n",
    "    vmin = None\n",
    "    vmax = None\n",
    "    bins_phs_1d = 300\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(14)\n",
    "    fig.set_figheight(4*number_rows)\n",
    "    for i, bus in enumerate(np.arange(bus_start, bus_stop+1, 1)):\n",
    "        plt.subplot(number_rows, 3, i+1)\n",
    "        clusters_bus = clusters[clusters.bus == bus]\n",
    "        clusters_uf_bus = clusters_unfiltered[clusters_unfiltered.bus == bus]\n",
    "        mg_basic_plot.phs_clusters_1d_plot(clusters_bus, clusters_uf_bus, bins_phs_1d, bus, duration)\n",
    "        plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Save data\n",
    "    output_path = '../output/%s_phs_1d.png' % run\n",
    "    fig.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    # Coincidences - 2D\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(14)\n",
    "    fig.set_figheight(4*number_rows)\n",
    "    if clusters.shape[0] != 0:\n",
    "        vmin = (1 * 1/duration)\n",
    "        vmax = (clusters.shape[0] // 450 + 5) * 1/duration\n",
    "    else:\n",
    "        duration = 1\n",
    "        vmin = 1\n",
    "        vmax = 1\n",
    "    for i, bus in enumerate(np.arange(bus_start, bus_stop+1, 1)):\n",
    "        plt.subplot(number_rows, 3, i+1)\n",
    "        clusters_bus = clusters[clusters.bus == bus]\n",
    "        # Calculate number of events and rate in a specific bus\n",
    "        number_events = clusters_bus.shape[0]\n",
    "        events_per_s = number_events/duration\n",
    "        events_per_s_m2 = events_per_s/area\n",
    "        title = ('Bus %d\\n(%d events, %.6f events/s/m$^2$)' % (bus, number_events, events_per_s_m2))\n",
    "        if number_events > 1:\n",
    "            mg_basic_plot.clusters_2d_plot(clusters_bus, title, vmin, vmax, duration)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Save data\n",
    "    output_path = '../output/%s_coincidences_2d.png' % run\n",
    "    fig.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    # Coincidences - PHS\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(14)\n",
    "    fig.set_figheight(4*number_rows)\n",
    "    if clusters.shape[0] != 0:\n",
    "        vmin = 1/duration\n",
    "        vmax = (clusters.shape[0] // 450 + 1000) / duration\n",
    "    else:\n",
    "        duration = 1\n",
    "        vmin = 1\n",
    "        vmax = 1\n",
    "    for i, bus in enumerate(np.arange(bus_start, bus_stop+1, 1)):\n",
    "        plt.subplot(number_rows, 3, i+1)\n",
    "        clusters_bus = clusters[clusters.bus == bus]\n",
    "        if clusters_bus.shape[0] > 1:\n",
    "            mg_basic_plot.clusters_phs_plot(clusters_bus, bus, duration, vmin, vmax)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Save data\n",
    "    output_path = '../output/%s_coincidences_phs.png' % run\n",
    "    fig.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    # Rate \n",
    "    number_bins = 50\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(14)\n",
    "    fig.set_figheight(4*number_rows)\n",
    "    for i, bus in enumerate(np.arange(bus_start, bus_stop+1, 1)):\n",
    "        plt.subplot(number_rows, 3, i+1)\n",
    "        clusters_bus = clusters[clusters.bus == bus]\n",
    "        mg_basic_plot.rate_plot(clusters_bus, number_bins, bus, area)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Save data\n",
    "    output_path = '../output/%s_rate.png' % run\n",
    "    fig.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    # TIME-OF-FLIGHT\n",
    "    number_bins = 300\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(14)\n",
    "    fig.set_figheight(4*number_rows)\n",
    "    for i, bus in enumerate(np.arange(bus_start, bus_stop+1, 1)):\n",
    "        plt.subplot(number_rows, 3, i+1)\n",
    "        clusters_bus = clusters[clusters.bus == bus]\n",
    "        mg_basic_plot.tof_histogram(clusters_bus, number_bins, bus)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Save data\n",
    "    output_path = '../output/%s_tof.png' % run\n",
    "    fig.savefig(output_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Paths<a class=\"anchor\" id=\"EXTRACT\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {'run_1': RAW_FOLDER + 'path_1.zip',\n",
    "         'run_2': RAW_FOLDER + 'path_2.zip',\n",
    "         'run_3': RAW_FOLDER + 'path_3.zip'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Extract<a class=\"anchor\" id=\"EXTRACT\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that the 'extract_and_save'-function only needs to performed once.\n",
    "# After that, the data has been clustered and saved. The data can then\n",
    "# be accessed using the 'load_clusters_and_events'-function.\n",
    "\n",
    "#extract_and_save('run_1', SEQUOIA_PATHS['run_1'])\n",
    "#extract_and_save('run_2', SEQUOIA_PATHS['run_2'])\n",
    "extract_and_save('run_3', SEQUOIA_PATHS['run_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Load<a class=\"anchor\" id=\"LOAD\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_run_1, ev_run_1 = load_clusters_and_events('run_1')\n",
    "clu_run_2, ev_run_2 = load_clusters_and_events('run_2')\n",
    "clu_run_3, ev_run_3 = load_clusters_and_events('run_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filters<a class=\"anchor\" id=\"FILTER\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare filters which can be used on the data. Below are a few template filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEQUOIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filters are declared in the following format: {'PARAMETER': [MIN_VALUE, MAX_VALUE, IS_ACTIVATE]}\n",
    "\"\"\"\n",
    "\n",
    "# Declare filters for SEQUOIA module\n",
    "mg_filter_basic = {'wm': [1, 1, True],                   # Wire multiplicity\n",
    "                   'gm': [1, 5, True],                   # Grid multiplicity\n",
    "                   'wadc': [600, np.inf, True],         # Wire charge\n",
    "                   'gadc': [600, np.inf, True],         # Grid charge\n",
    "                   'tof': [0, np.inf, True],             # Time-of-flight (TDC channels)\n",
    "                   'time': [0, np.inf, True],            # Time (TDC channels)\n",
    "                   'bus': [0, 8, True],                  # Bus\n",
    "                   'flag': [0, 1, False],                # =1 if different buses within same coincidence\n",
    "                   'layer': [0, 19, False],              # Layer, front=0 to back=19\n",
    "                   'row': [0, 11, False],                # Row, right to left (seen from neutrons)\n",
    "                   'gch': [80, 119, True]}               # Grid channel, bottom=80 to top=119          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plotting<a class=\"anchor\" id=\"FILTER\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_1 (data_set_name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area = 0.0225*0.0225*4*40\n",
    "plot_basic('sequoia_run_1', clu_sequoia_run_1, ev_sequoia_run_1, mg_filter_basic, 0, 5, 2, area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_2 (data_set_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area = 0.0225*0.0225*4*36\n",
    "plot_basic('sequoia_run_3', clu_sequoia_run_3, ev_sequoia_run_3, mg_filter_no_edges_no_back, 0, 5, 2, area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
